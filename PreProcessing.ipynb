{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of Concept  -  Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This brief report summarises the method used to preprocess the raw gestures data into manageable, database ready data. It is important that the data is free from errors at this stage as well as have values in a form that is also manageable for direct import into the database management system (MSSQL in this case). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The python libraries used for this pre-processing are well established in the data science field. We are creating and managing data with the use of the pandas DataFrame functionality and are also using the os library built-in to python to manage access to the local filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in developing the pre-processing system is to manage access to the raw data. For the Gestures data, each candidate's records were placed in a folder associated with a number. The files themselves are timestamped and associated with their parent folder. In order to obtain a database of individual records to access, a small helper function is required to traverse and collate each file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below establishes the location of the raw data and the output path in respect to the execution directory of the python code. The loop below simply prints, the file directory for these files which aligns to the filestructure of the raw data as explained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01,02,03,04,05,06,07,08,09,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,README.txt,"
     ]
    }
   ],
   "source": [
    "path_to_data = \"./Raw Data/gestures/\"\n",
    "output_path = \"./Raw Data/Formatted_Files/\"\n",
    "\n",
    "for dir in listdir(path_to_data):\n",
    "    print(dir, end=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code now produces a list of directories for the system to traverse to retreive data from. The difference between the direct listdir above and this code is that only subdirectories of the parent directory are listed. You can see this as the raw data's README.txt is not listed. This step was added as a simple way of ensuring that the raw data can be directly obtained and pre-processed before use without any need to manually modify any information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01,02,03,04,05,06,07,08,09,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,"
     ]
    }
   ],
   "source": [
    "folders = [dir for dir in listdir(path_to_data) if isdir(join(path_to_data, dir))]\n",
    "\n",
    "for dir in folders:\n",
    "    print(dir, end=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code that was used to prepare data for importing to the MSSQL database. The only difference being that the file was exported as a single csv file before importing. The basic process of this function is to obtain the list of files present in each folder as defined above. Once obtained, the system then reads the information directly as a tab seperated csv file (As the raw data is expressed). Also note that the usecols function strips the time information from the data. As this final system was a classification task, the requirement of time space information was deemed not necessary and has hence been excluded from the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the system has completed compiling all of the data into a single pandas DataFrame, some processing was performed on the data. Firstly, this involved removing the subset of the data with the class value equal to 0 as this corresponds to unlabeled data (as stated in the README). As these classes are not useful for training/validation of the chosen neural network, they are cleanly removed from every file. After this set of processing, the result was then shuffled to ensure that a random distribution of each subjects data was obtained. For the final neural network, this ensures that specific epochs are not biased towards the gestures of a single individual, rather a random subset of gestures from the entire pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel1</th>\n",
       "      <th>channel2</th>\n",
       "      <th>channel3</th>\n",
       "      <th>channel4</th>\n",
       "      <th>channel5</th>\n",
       "      <th>channel6</th>\n",
       "      <th>channel7</th>\n",
       "      <th>channel8</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00003</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.00005</td>\n",
       "      <td>-0.00005</td>\n",
       "      <td>-0.00005</td>\n",
       "      <td>-0.00005</td>\n",
       "      <td>-0.00003</td>\n",
       "      <td>-0.00003</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00004</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00056</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00024</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>-0.00033</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.00031</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.00013</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   channel1  channel2  channel3  channel4  channel5  channel6  channel7  \\\n",
       "0  -0.00001  -0.00003  -0.00001   0.00001   0.00001   0.00000  -0.00002   \n",
       "1  -0.00005  -0.00005  -0.00005  -0.00005  -0.00003  -0.00003  -0.00001   \n",
       "2   0.00005  -0.00002   0.00001   0.00004   0.00008   0.00009   0.00007   \n",
       "3   0.00056   0.00006   0.00002   0.00000  -0.00001  -0.00001   0.00006   \n",
       "4  -0.00001   0.00001   0.00018  -0.00033   0.00041   0.00031   0.00025   \n",
       "\n",
       "   channel8  class  \n",
       "0   0.00000    1.0  \n",
       "1  -0.00004    1.0  \n",
       "2   0.00011    3.0  \n",
       "3   0.00024    3.0  \n",
       "4   0.00013    5.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for folder in folders:\n",
    "    files = [f for f in listdir(path_to_data + folder + '/') if isfile(join(path_to_data + folder + '/', f))]\n",
    "    \n",
    "    for file in files:\n",
    "        df = pd.read_csv(path_to_data + folder + '/' + file, sep='\\t', header=0, usecols=range(1,10))\n",
    "        df.drop(df.loc[df['class']==0].index, inplace=True)\n",
    "        output_df = output_df.append(df)\n",
    "                \n",
    "output_df = output_df.sample(frac=1).reset_index(drop=True)     \n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final task is to analyse the final dataset. With the following info function available in pandas.DataFrame, we are able to see some high level information about the data. The total amount of records amounted to over 1.5 million with all values in every channel and class non-null. Although the values are expressed here as float64, the class variable will be modified to be an ungsigned integer in the database as a full 64 bit float value is considerably more storage than required for this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1512751 entries, 0 to 1512750\n",
      "Data columns (total 9 columns):\n",
      "channel1    1512751 non-null float64\n",
      "channel2    1512751 non-null float64\n",
      "channel3    1512751 non-null float64\n",
      "channel4    1512751 non-null float64\n",
      "channel5    1512751 non-null float64\n",
      "channel6    1512751 non-null float64\n",
      "channel7    1512751 non-null float64\n",
      "channel8    1512751 non-null float64\n",
      "class       1512750 non-null float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 103.9 MB\n"
     ]
    }
   ],
   "source": [
    "output_df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
